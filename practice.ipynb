{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import textwrap \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"The next geenration of AI for developers and Google Workspace\"\n",
    "sample_text = (\"Title: The next generation of AI for developers and Google Workspace\",)\n",
    "model = 'models/embedding-001'\n",
    "embedding = genai.embed_content(model=model,content=sample_text,task_type=\"retrieval_document\",\n",
    "title=title)\n",
    "print(embedding)\n",
    "print(len(embedding['embedding'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of text from PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "text = extract_text(r\"C:\\Users\\aanan\\Desktop\\My Folder\\Major Project_REPORT.pdf\")\n",
    "# split after every 5 sentences\n",
    "sentences = text.split(\".\")\n",
    "sentences = [\" \".join(sentences[i: i + 10]).replace('\\n',' ').strip() for i in range(0,len(sentences), 10)]\n",
    "for i in sentences:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for idx, i in enumerate(sentences):\n",
    "    documents.append({\n",
    "        'title': f\"Document {idx}\",\n",
    "        'content': i\n",
    "    })\n",
    "documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(documents)\n",
    "df.columns = ['Title', 'Text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings of each text and add to an embeddings column in the dataframe\n",
    "def embed_fn(title, text):\n",
    "    return genai.embed_content(\n",
    "        model=model,\n",
    "        content=text,\n",
    "        task_type=\"retrieval_document\",\n",
    "        title=title\n",
    "    )[\"embedding\"]\n",
    "\n",
    "df['Embeddings'] = df.apply(lambda row: embed_fn(row['Title'],row['Text']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question & its embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"The development server automatically\"\n",
    "model = 'models/embedding-001'\n",
    "\n",
    "request = genai.embed_content(\n",
    "    model=model,\n",
    "    content=query,\n",
    "    task_type=\"retrieval_query\"\n",
    ")\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_passage(query, dataframe):\n",
    "    \"\"\"\n",
    "    Compute the distances between the query and each document in the dataframe using the dot product\n",
    "    \"\"\"\n",
    "    \n",
    "    query_embedding = genai.embed_content(model=model,\n",
    "                                          content=query,\n",
    "                                          task_type=\"retrieval_query\")\n",
    "    dot_products = np.dot(np.stack(dataframe['Embeddings']), query_embedding[\"embedding\"])\n",
    "    idx = np.argmax(dot_products)\n",
    "    return dataframe.iloc[idx]['Text']  # Return text from index with max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = find_best_passage(query, df)\n",
    "passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_promp(query, relevant_passage):\n",
    "    escaped = relevant_passage.replace(\"'\",\"\").replace('\"',\"\").replace(\"\\n\",\" \") # escaped means to give data after cleaning\n",
    "    prompt = textwrap.dedent(\"\"\"You are a helpful and informative bot that answers \\\n",
    "    questions using text from the reference passage included below. \\\n",
    "    Be sure to respond in a complete sentence, being comprehensive, \\\n",
    "    including all relevant background information. \\\n",
    "    However, you are talking to a non-technical audience, \\\n",
    "    so be sure to break down complicated concepts and \\\n",
    "    strike a friendly and conversational tone. \\\n",
    "    If the passage is irrelevant to the answer, you may ignore it.\n",
    "    QUESTION : '{query}'\n",
    "    PASSAGE : '{relevant_passage}'\n",
    "    ANSWER :\n",
    "    \"\"\").format(query=query, relevant_passage=escaped)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = make_promp(query , passage)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('models/gemini-1.5-flash-latest')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
